# Pipeline Open Data - Fruits (OpenFoodFacts)

## ğŸ“‹ Description

Ce projet implÃ©mente un pipeline d'ingÃ©nierie des donnÃ©es automatisÃ© pour collecter, nettoyer et stocker des informations nutritionnelles sur les **fruits** depuis l'API publique OpenFoodFacts. Il est conÃ§u pour Ãªtre robuste, reproductible et facile Ã  Ã©tendre.

## ğŸ¯ Objectifs

- **Acquisition** : RÃ©cupÃ©rer ~1000 produits de la catÃ©gorie "fruits" via l'API v2.
- **Transformation** : Nettoyer les donnÃ©es (suppression doublons, gestion NULLs, typage strict).
- **Stockage** : Sauvegarder les donnÃ©es brutes (JSON) et raffinÃ©es (Parquet) pour analyse.
- **QualitÃ©** : Assurer l'intÃ©gritÃ© des donnÃ©es pour des analyses nutritionnelles.

## ğŸ› ï¸ Technologies utilisÃ©es

- ğŸ **Python 3.11+**
- ğŸ¼ **pandas** : Manipulation et nettoyage des donnÃ©es
- ğŸŒ **httpx** : RequÃªtes HTTP asynchrones/synchrones performantes
- ğŸ”„ **tenacity** : Gestion robuste des retries API
- ğŸ“Š **DuckDB** : Analyse SQL performante sur fichiers Parquet
- ğŸ“¦ **uv** : Gestionnaire de dÃ©pendances ultra-rapide

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.11 ou supÃ©rieur
- `uv` (recommandÃ©) ou `pip`

### Configuration

1. Cloner le dÃ©pÃ´t :
   ```bash
   git clone <url-du-repo>
   cd tp2-pipeline
   ```

2. Installer les dÃ©pendances :
   ```bash
   uv sync
   # ou
   pip install -r requirements.txt
   ```

### Variables d'environnement

CrÃ©er un fichier `.env` Ã  la racine (optionnel si pas d'auth) :

```env
# Exemple de configuration (si nÃ©cessaire)
API_KEY=votre_cle_api
```

## ğŸš€ Utilisation

### ExÃ©cution du pipeline

Pour lancer le pipeline complet (collecte -> nettoyage -> stockage) :

```bash
uv run python -m pipeline.main --name fruits
```

Cela va :
1. TÃ©lÃ©charger les donnÃ©es dans `data/raw/fruits_YYYYMMDD_HHMMSS.json`
2. Nettoyer les donnÃ©es
3. Sauvegarder le rÃ©sultat dans `data/processed/fruits_YYYYMMDD_HHMMSS.parquet`

### VÃ©rification des donnÃ©es

Pour analyser la qualitÃ© des fichiers gÃ©nÃ©rÃ©s :

```bash
uv run python verify_data.py
```

## ğŸ“Š Structure du projet

```
tp2-pipeline/
â”œâ”€â”€ data/                   # Stockage des donnÃ©es (ignorÃ© par git)
â”‚   â”œâ”€â”€ raw/                # Fichiers JSON bruts
â”‚   â””â”€â”€ processed/          # Fichiers Parquet nettoyÃ©s
â”œâ”€â”€ pipeline/               # Code source du pipeline
â”‚   â”œâ”€â”€ config.py           # Configuration globale
â”‚   â”œâ”€â”€ fetcher.py          # Module d'acquisition (API)
â”‚   â”œâ”€â”€ transformer.py      # Module de transformation (pandas)
â”‚   â”œâ”€â”€ storage.py          # Module de stockage (I/O)
â”‚   â””â”€â”€ main.py             # Script d'orchestration
â”œâ”€â”€ verify_data.py          # Script d'analyse qualitÃ©
â”œâ”€â”€ test_api.py             # Tests exploratoires API
â”œâ”€â”€ pyproject.toml          # DÃ©pendances (uv)
â””â”€â”€ README.md               # Documentation
```

## ğŸ” DonnÃ©es collectÃ©es

### Champs extraits

| Champ | Type | Description | Exemple |
|-------|------|-------------|---------|
| `code` | String | Code-barres unique (EAN) | "3274080005003" |
| `product_name` | String | Nom du produit | "Compote de Pomme" |
| `brands` | String | Marque | "Materne" |
| `categories` | String | CatÃ©gories (tags) | "Plant-based foods..." |
| `nutriscore_grade` | String | Note Nutri-Score (a-e) | "a" |
| `nova_group` | Int | Groupe NOVA (1-4) | 1 |
| `energy_100g` | Float | Ã‰nergie (kJ/100g) | 250.0 |
| `sugars_100g` | Float | Sucres (g/100g) | 12.5 |

### Statistiques Cibles

- **Volume** : ~1000 produits (~10 pages de 100)
- **Format** : Parquet (compression Snappy), optimisÃ© pour l'analytique.

## ğŸ§¹ Nettoyage effectuÃ©

Le module `transformer.py` applique les rÃ¨gles suivantes :
1. **DÃ©doublonnage** : Suppression des doublons basÃ©s sur le `code`.
2. **Filtrage** : Suppression des produits sans nom ou sans code.
3. **Imputation** :
   - Textes manquants â†’ "Unknown"
   - Valeurs nutritionnelles manquantes â†’ 0.0
   - Nutriscore manquant â†’ "unknown"
4. **Typage** : Conversion stricte vers les types cibles (int, float, string).
5. **Nettoyage texte** : Suppression des espaces superflus (strip).

## ğŸ“ˆ Exemples d'analyses possibles

Avec DuckDB, vous pouvez requÃªter directement le fichier Parquet :

```sql
-- Top 5 des fruits les plus sucrÃ©s
SELECT product_name, sugars_100g 
FROM 'data/processed/*.parquet' 
ORDER BY sugars_100g DESC 
LIMIT 5;

-- Distribution des Nutri-Scores
SELECT nutriscore_grade, count(*) as count 
FROM 'data/processed/*.parquet' 
GROUP BY nutriscore_grade;
```

## ğŸ› RÃ©solution de problÃ¨mes

**Erreur : "Rate limit exceeded"**
> Augmentez `API_RATE_LIMIT` dans `pipeline/config.py`.

**Erreur : "No products found"**
> VÃ©rifiez que l'API est accessible et que la catÃ©gorie "fruits" existe toujours.

## ğŸ“ Licence

TP acadÃ©mique - Usage Ã©ducatif uniquement dans le cadre du module Open Data & Data Engineering.

## ğŸ‘¤ Auteur

**TP2 Data Engineering**
